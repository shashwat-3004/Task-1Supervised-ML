---
title: "Supervised-ML"
author: "Shashwat Patel"
date: "03/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)
```
# Attaching the required packages

```{r}
library(tidyverse)
library(caTools)
library(gridExtra)
library(Metrics)
```

# Read the data
```{r}
data<-read_csv("score.csv")
```

```{r}
head(data)
```
# Basic summary of the data
```{r}
summary(data)
```
**In the below plot, it can be clearly seen that Scores and Hours have some what a linear relationship between them, so linear regrression makes good fit for the data.**

```{r}
data%>% ggplot()+ geom_point(aes(x=Hours,y=Scores),colour="blue")+
          geom_smooth(aes(x=Hours,y=Scores),method = "lm",formula = y~x,se=FALSE,colour="red")+
          ggtitle("Score vs Hours of the data")+theme(plot.title=element_text(hjust=0.5))
```


**There is no outlier as well, clearly seen from the boxplots**

```{r}
p1<-data%>% ggplot()+geom_boxplot(aes(y=Hours))

p2<-data%>% ggplot()+geom_boxplot(aes(y=Scores))
grid.arrange(p1,p2,nrow=1)
```


### **Splitting the data in training set and test set.**

```{r}
set.seed(2)
split<-sample.split(data$Hours,SplitRatio = 0.8)
training_data<-subset(data,split==TRUE)
test_data<-subset(data,split==FALSE)
```

### **Fitting the linear model**

- The results reject the null hypothesis. 

- The p-value of Hours variable is very low, so Hour variable is highly significant.

- Its t value is also high as compared with standard error.

- Adjusted R-squared is 0.9428, showing significant relationship between Hours variable and the dependent Score data.

```{r}
regressor<-lm(formula=Scores~Hours,data = training_data)
summary(regressor)
```
- Corrleation btween Hour and Score also suggest a strong relationship.
```{r}
cor(data$Hours,data$Scores)
```

### **Prediction scores for test set**

```{r}
score_prediction<-predict(regressor,newdata=test_data)
act_pred_data<-data.frame(Hours=test_data$Hours,Actual_score=test_data$Scores,Predicted_score=score_prediction)
act_pred_data
```

**In the 1st plot, the model is fitted on training set and we can see the regression line as well as training data, In the 2nd plot the model is fitted on test set and regression line is also present.**  
```{r}
pl1<-ggplot()+geom_point(aes(x=training_data$Hours,y=training_data$Scores),colour="blue")+
     geom_line(aes(x=training_data$Hours,y=predict(regressor,training_data)))+ggtitle("Score vs Hours(Training_set) ")+xlab("Hours") +
  ylab("Scores")
pl2<-ggplot()+geom_point(aes(x=test_data$Hours,y=test_data$Scores),colour="blue")+
     geom_line(aes(x=test_data$Hours,y=score_prediction),colour="red")+ggtitle("Score vs Hours(Test_set") +
  xlab("Hours") +
  ylab("Scores")
grid.arrange(pl1,pl2,nrow=1)


```


### **The predicted score for a student who studied for 9.5 hours**

```{r}
new_data<-data.frame(Hours=9.5,Score=NA)
Predicted_score<-predict(regressor,new_data)
Predicted_score
```

# Model Accuracy

**It shows the mean absolute error is 4.567176, and root mean sqaured error is 4.9404. These are prettly low, which suggests that our model is pretty accurate.** 

```{r}
mean_absolute_error<-mae(act_pred_data$Actual_score,act_pred_data$Predicted_score)
root_mean_squared_error<-rmse(act_pred_data$Actual_score,act_pred_data$Predicted_score)
root_mean_squared_error
mean_absolute_error
```

